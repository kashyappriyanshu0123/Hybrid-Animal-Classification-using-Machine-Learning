{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vg0U8vkCQVYb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74f8d212-7db0-41d1-cc51-2892b4f54da8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "metadata": {
        "id": "RHp38JkJHi39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5241bb10-07a9-48ca-df93-dd016582305f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.6)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.10.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n",
        "!pip install opencv-python"
      ],
      "metadata": {
        "id": "uuYazVZ5Llr2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86794757-d8fa-448c-f53a-4597cf52baba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.12.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.10/dist-packages (from scikeras) (23.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.3.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.12.0\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jnXGpMUcSqXD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imread\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from PIL import Image\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fjwa3TeRTs7h"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/Hybrid Animals'\n",
        "beefalos = os.path.join(data_dir, 'beefalo')\n",
        "for beefalo in os.listdir(beefalos):\n",
        "\n",
        "  img_path = os.path.join(beefalos, beefalo)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(0)\n",
        "\n",
        "\n",
        "coywolves = os.path.join(data_dir, 'coywolf')\n",
        "for coywolf in os.listdir(coywolves):\n",
        "\n",
        "  img_path = os.path.join(coywolves, coywolf)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(1)\n",
        "\n",
        "\n",
        "geeps = os.path.join(data_dir, 'geep')\n",
        "for geep in os.listdir(geeps):\n",
        "\n",
        "  img_path = os.path.join(geeps, geep)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(2)\n",
        "\n",
        "\n",
        "ligers = os.path.join(data_dir, 'liger')\n",
        "for liger in os.listdir(ligers):\n",
        "\n",
        "  img_path = os.path.join(ligers, liger)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(3)\n",
        "\n",
        "\n",
        "mules = os.path.join(data_dir, 'mule')\n",
        "for mule in os.listdir(mules):\n",
        "\n",
        "  img_path = os.path.join(mules, mule)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(4)\n",
        "\n",
        "\n",
        "ocicats = os.path.join(data_dir, 'ocicat')\n",
        "for ocicat in os.listdir(ocicats):\n",
        "\n",
        "  img_path = os.path.join(ocicats, ocicat)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(5)\n",
        "\n",
        "\n",
        "pizzlies = os.path.join(data_dir, 'pizzly')\n",
        "for pizzly in os.listdir(pizzlies):\n",
        "\n",
        "  img_path = os.path.join(pizzlies, pizzly)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(6)\n",
        "\n",
        "\n",
        "pumapards = os.path.join(data_dir, 'pumapard')\n",
        "for pumapard in os.listdir(pumapards):\n",
        "\n",
        "  img_path = os.path.join(pumapards, pumapard)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(7)\n",
        "\n",
        "\n",
        "snow_capped_manakins = os.path.join(data_dir, 'snow capped manakin')\n",
        "for snow_capped_manakin in os.listdir(snow_capped_manakins):\n",
        "\n",
        "  img_path = os.path.join(snow_capped_manakins, snow_capped_manakin)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(8)\n",
        "\n",
        "\n",
        "welsh_corgis = os.path.join(data_dir, 'welsh corgi')\n",
        "for welsh_corgi in os.listdir(welsh_corgis):\n",
        "\n",
        "  img_path = os.path.join(welsh_corgis, welsh_corgi)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(9)\n",
        "\n",
        "\n",
        "wholphins = os.path.join(data_dir, 'wholphin')\n",
        "for wholphin in os.listdir(wholphins):\n",
        "\n",
        "  img_path = os.path.join(wholphins, wholphin)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(10)\n",
        "\n",
        "\n",
        "wolfdogs = os.path.join(data_dir, 'wolfdog')\n",
        "for wolfdog in os.listdir(wolfdogs):\n",
        "\n",
        "  img_path = os.path.join(wolfdogs, wolfdog)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(11)\n",
        "\n",
        "\n",
        "zonkies = os.path.join(data_dir, 'zonkey')\n",
        "for zonkey in os.listdir(zonkies):\n",
        "\n",
        "  img_path = os.path.join(zonkies, zonkey)\n",
        "  print(img_path)\n",
        "  if not img_path.lower().endswith(('.png', '.jpg', '.jpeg')) or os.path.getsize(img_path) == 0:\n",
        "            print(f\"Skipping non-image file or file with size 0: {img_path}\")\n",
        "            continue\n",
        "  imag = cv2.imread(img_path)\n",
        "  if imag is None:\n",
        "    continue\n",
        "  img_from_ar = Image.fromarray(imag, 'RGB')\n",
        "  resized_image = img_from_ar.resize((50, 50))\n",
        "  data.append(np.array(resized_image))\n",
        "  labels.append(12)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "animals = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "LUbLZAKHZ4Zt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.save(\"animals\", animals)\n",
        "np.save(\"labels\", labels)"
      ],
      "metadata": {
        "id": "64B6vJf4aDEF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "animals = np.load(\"/content/animals.npy\")\n",
        "labels = np.load(\"/content/labels.npy\")"
      ],
      "metadata": {
        "id": "h3AZYg_AaLqV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = np.arange(animals.shape[0])\n",
        "np.random.shuffle(s)\n",
        "animals=animals[s]\n",
        "labels = labels[s]"
      ],
      "metadata": {
        "id": "vs8rxPoKajTX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(np.unique(labels))\n",
        "data_length = len(animals)"
      ],
      "metadata": {
        "id": "MbJz2koDayew"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,x_test)=animals[(int)(0.1*data_length):],animals[:(int)(0.1*data_length)]\n",
        "x_train = x_train.astype('float32')/255\n",
        "x_test = x_test.astype('float32')/255\n",
        "train_length=len(x_train)\n",
        "test_length=len(x_test)\n",
        "(y_train,y_test)=labels[(int)(0.1*data_length):],labels[:(int)(0.1*data_length)]"
      ],
      "metadata": {
        "id": "z6asI0KKa9Cy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test=keras.utils.to_categorical(y_test,num_classes)"
      ],
      "metadata": {
        "id": "Y574QIMgbJJG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "\n",
        "model=Sequential()\n",
        "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(50,50,3)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500,activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(13,activation=\"softmax\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwdWpgH3byxH",
        "outputId": "3cfc4850-af88-49b4-a6c5-3c4f7258414a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 50, 50, 16)        208       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 25, 25, 16)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 25, 25, 32)        2080      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 12, 12, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               1152500   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 13)                6513      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1169557 (4.46 MB)\n",
            "Trainable params: 1169557 (4.46 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
        "                  metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "p0-nasRTcAyp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train,y_train,batch_size=50\n",
        "          ,epochs=100,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Cll1qmNcDvC",
        "outputId": "77fda8a2-b44d-415a-8d48-1021c8841c3e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "72/72 [==============================] - 7s 9ms/step - loss: 2.3184 - accuracy: 0.2147\n",
            "Epoch 2/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.9524 - accuracy: 0.3532\n",
            "Epoch 3/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.7045 - accuracy: 0.4472\n",
            "Epoch 4/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.5541 - accuracy: 0.4992\n",
            "Epoch 5/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.3883 - accuracy: 0.5617\n",
            "Epoch 6/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.2839 - accuracy: 0.5955\n",
            "Epoch 7/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.1537 - accuracy: 0.6441\n",
            "Epoch 8/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 1.0421 - accuracy: 0.6767\n",
            "Epoch 9/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.9179 - accuracy: 0.7085\n",
            "Epoch 10/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.8260 - accuracy: 0.7418\n",
            "Epoch 11/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.7461 - accuracy: 0.7708\n",
            "Epoch 12/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.6744 - accuracy: 0.7898\n",
            "Epoch 13/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.5742 - accuracy: 0.8205\n",
            "Epoch 14/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.8465\n",
            "Epoch 15/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.8685\n",
            "Epoch 16/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8855\n",
            "Epoch 17/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.3314 - accuracy: 0.8995\n",
            "Epoch 18/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2827 - accuracy: 0.9182\n",
            "Epoch 19/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.2315 - accuracy: 0.9347\n",
            "Epoch 20/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.2082 - accuracy: 0.9405\n",
            "Epoch 21/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.1817 - accuracy: 0.9511\n",
            "Epoch 22/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.1745 - accuracy: 0.9492\n",
            "Epoch 23/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.1414 - accuracy: 0.9609\n",
            "Epoch 24/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.1398 - accuracy: 0.9618\n",
            "Epoch 25/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9712\n",
            "Epoch 26/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0993 - accuracy: 0.9732\n",
            "Epoch 27/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.1081 - accuracy: 0.9679\n",
            "Epoch 28/100\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.0817 - accuracy: 0.9788\n",
            "Epoch 29/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0921 - accuracy: 0.9729\n",
            "Epoch 30/100\n",
            "72/72 [==============================] - 1s 7ms/step - loss: 0.0708 - accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0659 - accuracy: 0.9813\n",
            "Epoch 32/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9782\n",
            "Epoch 33/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9824\n",
            "Epoch 34/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0543 - accuracy: 0.9846\n",
            "Epoch 35/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0598 - accuracy: 0.9858\n",
            "Epoch 36/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0496 - accuracy: 0.9872\n",
            "Epoch 37/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0466 - accuracy: 0.9888\n",
            "Epoch 38/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0584 - accuracy: 0.9832\n",
            "Epoch 39/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9872\n",
            "Epoch 40/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0471 - accuracy: 0.9855\n",
            "Epoch 41/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0499 - accuracy: 0.9894\n",
            "Epoch 42/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9911\n",
            "Epoch 43/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0422 - accuracy: 0.9886\n",
            "Epoch 44/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9936\n",
            "Epoch 45/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0315 - accuracy: 0.9919\n",
            "Epoch 46/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9894\n",
            "Epoch 47/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0545 - accuracy: 0.9860\n",
            "Epoch 48/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0407 - accuracy: 0.9902\n",
            "Epoch 49/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9913\n",
            "Epoch 50/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9919\n",
            "Epoch 51/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0393 - accuracy: 0.9899\n",
            "Epoch 52/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0379 - accuracy: 0.9880\n",
            "Epoch 53/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9894\n",
            "Epoch 54/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0335 - accuracy: 0.9911\n",
            "Epoch 55/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0301 - accuracy: 0.9913\n",
            "Epoch 56/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0318 - accuracy: 0.9899\n",
            "Epoch 57/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0285 - accuracy: 0.9913\n",
            "Epoch 58/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9919\n",
            "Epoch 59/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0295 - accuracy: 0.9902\n",
            "Epoch 60/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0373 - accuracy: 0.9894\n",
            "Epoch 61/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0236 - accuracy: 0.9941\n",
            "Epoch 62/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0343 - accuracy: 0.9899\n",
            "Epoch 63/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0285 - accuracy: 0.9930\n",
            "Epoch 64/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9897\n",
            "Epoch 65/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0439 - accuracy: 0.9860\n",
            "Epoch 66/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0221 - accuracy: 0.9930\n",
            "Epoch 67/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0321 - accuracy: 0.9911\n",
            "Epoch 68/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 0.9950\n",
            "Epoch 69/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0395 - accuracy: 0.9919\n",
            "Epoch 70/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9930\n",
            "Epoch 71/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9930\n",
            "Epoch 72/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0224 - accuracy: 0.9939\n",
            "Epoch 73/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0308 - accuracy: 0.9905\n",
            "Epoch 74/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0208 - accuracy: 0.9947\n",
            "Epoch 75/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0216 - accuracy: 0.9941\n",
            "Epoch 76/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9947\n",
            "Epoch 77/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0119 - accuracy: 0.9978\n",
            "Epoch 78/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0203 - accuracy: 0.9941\n",
            "Epoch 79/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0175 - accuracy: 0.9939\n",
            "Epoch 80/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0295 - accuracy: 0.9911\n",
            "Epoch 81/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0307 - accuracy: 0.9913\n",
            "Epoch 82/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0166 - accuracy: 0.9953\n",
            "Epoch 83/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0170 - accuracy: 0.9961\n",
            "Epoch 84/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9913\n",
            "Epoch 85/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0261 - accuracy: 0.9927\n",
            "Epoch 86/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.9891\n",
            "Epoch 87/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0551 - accuracy: 0.9807\n",
            "Epoch 88/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0380 - accuracy: 0.9872\n",
            "Epoch 89/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0343 - accuracy: 0.9888\n",
            "Epoch 90/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0463 - accuracy: 0.9852\n",
            "Epoch 91/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0210 - accuracy: 0.9933\n",
            "Epoch 92/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0184 - accuracy: 0.9953\n",
            "Epoch 93/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0241 - accuracy: 0.9916\n",
            "Epoch 94/100\n",
            "72/72 [==============================] - 0s 5ms/step - loss: 0.0183 - accuracy: 0.9933\n",
            "Epoch 95/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9941\n",
            "Epoch 96/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0142 - accuracy: 0.9964\n",
            "Epoch 97/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0091 - accuracy: 0.9978\n",
            "Epoch 98/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 0.9964\n",
            "Epoch 99/100\n",
            "72/72 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 0.9953\n",
            "Epoch 100/100\n",
            "72/72 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.9950\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "metadata": {
        "id": "WIVu80UQzhD_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Assuming model.predict returns probabilities\n",
        "y_pred_probs = model.predict(x_test)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Generate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_true, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "id": "BNfZ68gbzq_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20f53d35-7213-4b79-82a1-1606676066ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 4ms/step\n",
            "Confusion Matrix:\n",
            "[[16  0  0  1  2  0  1  0  2  0  0  0  2]\n",
            " [ 0 17  0  1  1  0  0  1  1  0  0  2  0]\n",
            " [ 0  0  8  0  0  0  0  0  0  1  0  1  1]\n",
            " [ 0  1  1 13  0  1  1  4  1  0  0  2  1]\n",
            " [ 4  0  0  3  6  2  0  1  0  0  0  1  4]\n",
            " [ 1  3  0  0  1 26  1  5  4  1  3  1  1]\n",
            " [ 2  0  0  0  0  1 17  1  2  2  0  1  1]\n",
            " [ 1  3  0  2  1  0  3 21  5  0  0  0  5]\n",
            " [ 0  1  1  0  1  0  0  0 29  0  0  0  0]\n",
            " [ 2  3  0  3  0  2  0  0  3 39  1  2  0]\n",
            " [ 1  0  0  0  0  1  0  1  1  0 24  1  0]\n",
            " [ 1  2  1  0  2  0  1  1  2  2  1 20  2]\n",
            " [ 1  2  1  1  0  1  0  0  0  1  0  0 21]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.67      0.60        24\n",
            "           1       0.53      0.74      0.62        23\n",
            "           2       0.67      0.73      0.70        11\n",
            "           3       0.54      0.52      0.53        25\n",
            "           4       0.43      0.29      0.34        21\n",
            "           5       0.76      0.55      0.64        47\n",
            "           6       0.71      0.63      0.67        27\n",
            "           7       0.60      0.51      0.55        41\n",
            "           8       0.58      0.91      0.71        32\n",
            "           9       0.85      0.71      0.77        55\n",
            "          10       0.83      0.83      0.83        29\n",
            "          11       0.65      0.57      0.61        35\n",
            "          12       0.55      0.75      0.64        28\n",
            "\n",
            "    accuracy                           0.65       398\n",
            "   macro avg       0.63      0.65      0.63       398\n",
            "weighted avg       0.66      0.65      0.64       398\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDH8tjitV3X6",
        "outputId": "dc8de052-32c2-4afe-bba5-6aa9722e684c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 5ms/step - loss: 2.5253 - accuracy: 0.6457\n",
            "\n",
            " Test accuracy: 0.6457286477088928\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=1)\n",
        "print('\\n', 'Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_array(img):\n",
        "    im = cv2.imread(img)\n",
        "    img = Image.fromarray(im, 'RGB')\n",
        "    image = img.resize((50, 50))\n",
        "    return np.array(image)\n",
        "def get_animal_name(label):\n",
        "    if label==0:\n",
        "        return \"beefalo\"\n",
        "    if label==1:\n",
        "        return \"coywolf\"\n",
        "    if label==2:\n",
        "        return \"geep\"\n",
        "    if label==3:\n",
        "        return \"liger\"\n",
        "    if label==4:\n",
        "        return \"mule\"\n",
        "    if label==5:\n",
        "        return \"ocicat\"\n",
        "    if label==6:\n",
        "        return \"pizzly\"\n",
        "    if label==7:\n",
        "        return \"pumapard\"\n",
        "    if label==8:\n",
        "        return \"snow capped manakin\"\n",
        "    if label==9:\n",
        "        return \"welsh corgi\"\n",
        "    if label==10:\n",
        "        return \"wholphin\"\n",
        "    if label==11:\n",
        "        return \"wolfdog\"\n",
        "    if label == 12:\n",
        "        return \"zonkey\"\n",
        "def predict_animal(file):\n",
        "    print(\"Predicting .................................\")\n",
        "    ar=convert_to_array(file)\n",
        "    ar=ar/255\n",
        "    label=1\n",
        "    a=[]\n",
        "    a.append(ar)\n",
        "    a=np.array(a)\n",
        "    score=model.predict(a,verbose=1)\n",
        "    print(score)\n",
        "    label_index=np.argmax(score)\n",
        "    print(label_index)\n",
        "    acc=np.max(score)\n",
        "    animal=get_animal_name(label_index)\n",
        "    print(animal)\n",
        "    print(\"The predicted Animal is a \"+animal+\" with accuracy =    \"+str(acc))"
      ],
      "metadata": {
        "id": "ZkvCWFXAwQeJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_animal(\"/content/drive/MyDrive/Hybrid Animals/liger/th-1031154384.jpeg\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtuCjEsYxE2N",
        "outputId": "48c3a9a7-6236-4ed8-b088-5b60dee8313b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting .................................\n",
            "1/1 [==============================] - 0s 234ms/step\n",
            "[[7.6024690e-14 2.2075901e-09 3.0372931e-16 9.9999392e-01 6.2630452e-12\n",
            "  1.1251955e-13 6.9682628e-11 5.8629644e-06 1.2054513e-13 2.3874591e-07\n",
            "  1.1790163e-18 5.0249309e-08 1.0468316e-12]]\n",
            "3\n",
            "liger\n",
            "The predicted Animal is a liger with accuracy =    0.9999939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ii7HkAdYXK_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}